{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning using LSTM for Review Ratings Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction and Preprocessing (we follow the same process as in data_cleaning but we keep a different sample of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from cleantext import clean\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from deep_translator import GoogleTranslator\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_link</th>\n",
       "      <th>company_link</th>\n",
       "      <th>company_name</th>\n",
       "      <th>score</th>\n",
       "      <th>description</th>\n",
       "      <th>review_page_nb</th>\n",
       "      <th>review_link</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://fr.trustpilot.com/categories/food_beve...</td>\n",
       "      <td>https://fr.trustpilot.com/review/lefourgon.com</td>\n",
       "      <td>Le Fourgon</td>\n",
       "      <td>4,9</td>\n",
       "      <td>Le Fourgon vous livre vos boissons consignées ...</td>\n",
       "      <td>329</td>\n",
       "      <td>https://fr.trustpilot.com/reviews/65a5388a60d6...</td>\n",
       "      <td>5</td>\n",
       "      <td>Application conviviale pour passer ses…</td>\n",
       "      <td>Application conviviale pour passer ses command...</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://fr.trustpilot.com/categories/food_beve...</td>\n",
       "      <td>https://fr.trustpilot.com/review/lefourgon.com</td>\n",
       "      <td>Le Fourgon</td>\n",
       "      <td>4,9</td>\n",
       "      <td>Le Fourgon vous livre vos boissons consignées ...</td>\n",
       "      <td>329</td>\n",
       "      <td>https://fr.trustpilot.com/reviews/65a53245a223...</td>\n",
       "      <td>5</td>\n",
       "      <td>Très facile pour la commande</td>\n",
       "      <td>Très facile pour la commande, très rapide et l...</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://fr.trustpilot.com/categories/food_beve...</td>\n",
       "      <td>https://fr.trustpilot.com/review/lefourgon.com</td>\n",
       "      <td>Le Fourgon</td>\n",
       "      <td>4,9</td>\n",
       "      <td>Le Fourgon vous livre vos boissons consignées ...</td>\n",
       "      <td>329</td>\n",
       "      <td>https://fr.trustpilot.com/reviews/659f0e15dd57...</td>\n",
       "      <td>5</td>\n",
       "      <td>Première expérience réussie !</td>\n",
       "      <td>Pour nous, c'était une première.Ravis d'avoir ...</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       category_link  ...                category\n",
       "0  https://fr.trustpilot.com/categories/food_beve...  ...  food_beverages_tobacco\n",
       "1  https://fr.trustpilot.com/categories/food_beve...  ...  food_beverages_tobacco\n",
       "2  https://fr.trustpilot.com/categories/food_beve...  ...  food_beverages_tobacco\n",
       "\n",
       "[3 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv(\"data/reviews.csv\", sep=\";\")\n",
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df[[\"company_name\", \"score\", \"review_score\", \"review_title\", \"review_text\", \"category\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We merge the review title and the review text into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>score</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>category</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le Fourgon</td>\n",
       "      <td>4,9</td>\n",
       "      <td>5</td>\n",
       "      <td>Application conviviale pour passer ses…</td>\n",
       "      <td>Application conviviale pour passer ses command...</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "      <td>Application conviviale pour passer ses… Applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le Fourgon</td>\n",
       "      <td>4,9</td>\n",
       "      <td>5</td>\n",
       "      <td>Très facile pour la commande</td>\n",
       "      <td>Très facile pour la commande, très rapide et l...</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "      <td>Très facile pour la commande Très facile pour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le Fourgon</td>\n",
       "      <td>4,9</td>\n",
       "      <td>5</td>\n",
       "      <td>Première expérience réussie !</td>\n",
       "      <td>Pour nous, c'était une première.Ravis d'avoir ...</td>\n",
       "      <td>food_beverages_tobacco</td>\n",
       "      <td>Première expérience réussie ! Pour nous, c'éta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name  ...                                             review\n",
       "0  Le Fourgon   ...  Application conviviale pour passer ses… Applic...\n",
       "1  Le Fourgon   ...  Très facile pour la commande Très facile pour ...\n",
       "2  Le Fourgon   ...  Première expérience réussie ! Pour nous, c'éta...\n",
       "\n",
       "[3 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we merge the title and the text of the review\n",
    "reviews_df[\"review\"] = reviews_df[\"review_title\"] + \" \" + reviews_df[\"review_text\"]\n",
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Application conviviale pour passer ses Application conviviale pour passer ses commandes. Manquent juste les ingredients pas evidents a trouver.Notification par SMS peu de temps avant le creneau choisi pour un creneau precis de 20 minutes.Livreurs agreables.Merci le Fourgon !'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(reviews_df[\"review\"].values[0], no_emoji=True, no_line_breaks=True, lower=False).replace(\"#\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df[\"review\"] = reviews_df[\"review\"].apply(lambda x: clean(x, no_emoji=True, no_line_breaks=True, lower=False).replace(\"#\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Exceptionnel La brulerie Belleville est devenue mon unique fournisseur en cafe, le cafe est vraiment d'une qualite exceptionnelle ! De plus, le service apres-vente est d'une qualite humaine devenue bien rare a present !\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[\"review\"].values[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12996"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of companies in the dataset\n",
    "len(reviews_df[\"company_name\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We Keep only a sample of the data (the top 1000 companies with the most reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name\n",
       "Hardloop                            236\n",
       "Alltricks                           210\n",
       "Ekosport                            140\n",
       "vertbaudet                          140\n",
       "Mode Tactique                       120\n",
       "                                   ... \n",
       "Les Bons Profs                       40\n",
       "L'école de secrétariat d'Emilie      40\n",
       "Sosbilan                             40\n",
       "Tuto Mix                             40\n",
       "Marmon Sports                        40\n",
       "Name: count, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of reviews per company\n",
    "reviews_df[\"company_name\"].value_counts()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235503"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of reviews in all the dataset\n",
    "len(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hardloop\\xa0'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first company name\n",
    "reviews_df[\"company_name\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hardloop'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[\"company_name\"] = reviews_df[\"company_name\"].apply(lambda x: x.replace(\"\\xa0\", \"\") if x != \"\\xa0\" else x)\n",
    "reviews_df[\"company_name\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51768"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we keep only the reviews of the first 100 companies in terms of number of reviews\n",
    "revsample_df = reviews_df[reviews_df[\"company_name\"].isin(reviews_df[\"company_name\"].value_counts()[:1000].index)]\n",
    "revsample_df[\"company_name\"].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name\n",
       "Hardloop          236\n",
       "Alltricks         210\n",
       "Ekosport          140\n",
       "vertbaudet        140\n",
       "Weenect           120\n",
       "Mode Tactique     120\n",
       "AAAEP             120\n",
       "Handball Store    111\n",
       "Meyclub           100\n",
       "eevad             100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revsample_df[\"company_name\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "revsample_df = revsample_df.dropna(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we display all the lines of the first company\n",
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "# revsample_df[revsample_df[\"company_name\"] == \"Hardloop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We keep only the reviews in french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detecte_langage(message):\n",
    "    # we define an empty dictionary\n",
    "    # {language : number of common stopwords between the language and the words of the message}\n",
    "    languages_shared_words = {}\n",
    "    # tokenization in words\n",
    "    words = wordpunct_tokenize(message)\n",
    "    for language in stopwords.fileids():\n",
    "        # stopwords for each language\n",
    "        stopwords_liste = stopwords.words(language)\n",
    "        # we take off the duplicates\n",
    "        words = set(words)\n",
    "        # the common words between the stopwords of a language and the words of the message\n",
    "        common_elements = words.intersection(stopwords_liste)\n",
    "        # addition of the couple to the dictionary\n",
    "        languages_shared_words[language] = len(common_elements)\n",
    "    # we return the language with the max of common words\n",
    "    return  max(languages_shared_words, key = languages_shared_words.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we apply the function for each message on the review column and we keep only the lines where the language is in French // 6min 55 for 52000 reviews\n",
    "revsample_df[\"langue\"] = revsample_df[\"review\"].apply(detecte_langage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name    46324\n",
       "score           46324\n",
       "review_score    46324\n",
       "review_title    46324\n",
       "review_text     46324\n",
       "category        46324\n",
       "review          46324\n",
       "langue          46324\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revsample_df[revsample_df[\"langue\"] == \"french\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "revsample_df_fr = revsample_df[revsample_df[\"langue\"] == \"french\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "revsample_df_fr.to_csv(\"data/revsample_df_fr.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With RNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "revsample_df_fr = pd.read_csv(\"data/revsample_df_fr.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_score\n",
       "5    34443\n",
       "1     4647\n",
       "4     4418\n",
       "3     1702\n",
       "2     1114\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want balanced classes in the train dataset. \n",
    "# let's see the number of reviews per score in the train and test datasets. The scores are between 1 and 5.\n",
    "revsample_df_fr[\"review_score\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We Use the UnderSampling method to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gdetr\\AppData\\Local\\Temp\\ipykernel_33776\\860641243.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  revsample_df_fr = revsample_df_fr.groupby(\"review_score\").apply(lambda x: x.sample(1114, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "review_score\n",
       "1    1114\n",
       "2    1114\n",
       "3    1114\n",
       "4    1114\n",
       "5    1114\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we keep only 1114 random reviews per score in the train dataset\n",
    "revsample_df_fr = revsample_df_fr.groupby(\"review_score\").apply(lambda x: x.sample(1114, random_state=42)).reset_index(drop=True)\n",
    "revsample_df_fr[\"review_score\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4456, 9), (1114, 9))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we split the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(revsample_df_fr, test_size=0.2, random_state=42)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to encode the reviews with a max_length of 500\n",
    "# max_length = 500\n",
    "# def encode_reviews(tokenizer, reviews, max_length):\n",
    "#     token_ids = np.zeros(shape=(len(reviews), max_length),\n",
    "#                          dtype=np.int32)\n",
    "#     for i, review in enumerate(reviews):\n",
    "#         encoded = tokenizer.encode(review, max_length=max_length, truncation=True)\n",
    "#         token_ids[i, 0:len(encoded)] = encoded\n",
    "#     attention_mask = (token_ids != 0).astype(np.int32)\n",
    "#     return {\"input_ids\": token_ids, \"attention_mask\": attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we encode the reviews\n",
    "# train_encoded = encode_reviews(tokenizer, train[\"review\"].values, max_length)\n",
    "# test_encoded = encode_reviews(tokenizer, test[\"review\"].values, max_length)\n",
    "# train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, ..., 5, 5, 1], dtype=int64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creation of train and test labels\n",
    "train_labels = train[\"review_score\"].values\n",
    "test_labels = test[\"review_score\"].values\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "#we verify the range of the labels (between 0 and 5) in the train and test datasets\n",
    "print(np.unique(train_labels))\n",
    "print(np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we one hot encode the labels that are currently between 1 and 5 using to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels - 1)\n",
    "test_labels = to_categorical(test_labels - 1)\n",
    "\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librairies importation for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With RNN-LSTM model\n",
    "import keras as keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, BatchNormalization, Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization and Padding of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[291,\n",
       " 2,\n",
       " 6,\n",
       " 34,\n",
       " 14,\n",
       " 207,\n",
       " 121,\n",
       " 343,\n",
       " 2,\n",
       " 34,\n",
       " 24,\n",
       " 49,\n",
       " 15,\n",
       " 418,\n",
       " 30,\n",
       " 97,\n",
       " 2418,\n",
       " 32,\n",
       " 93,\n",
       " 130,\n",
       " 19,\n",
       " 43,\n",
       " 3,\n",
       " 70,\n",
       " 418,\n",
       " 363,\n",
       " 2,\n",
       " 248,\n",
       " 15,\n",
       " 378,\n",
       " 52,\n",
       " 7,\n",
       " 21,\n",
       " 1446,\n",
       " 8,\n",
       " 1,\n",
       " 784,\n",
       " 68,\n",
       " 207,\n",
       " 88,\n",
       " 9,\n",
       " 3956,\n",
       " 1970,\n",
       " 375]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we tokenize the reviews\n",
    "top_words = 5000\n",
    "tokenizer = Tokenizer(num_words=top_words, oov_token=\"<OOV>\", filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train[\"review\"].values)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train[\"review\"].values)\n",
    "test_sequences = tokenizer.texts_to_sequences(test[\"review\"].values)\n",
    "\n",
    "train_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1517, 1984,  123,   20,    5,   39,   29,   16,  407,  102,  744,\n",
       "          2,    1, 2851, 3165,    2, 3500,  821,  353,   17,   51,    5,\n",
       "        788,   29,   16,  407,  584, 2852,    2, 3500,   61,   29,   36,\n",
       "        341,  102,   78,    4,    1,  632,   10,  788,    2, 1517, 1984,\n",
       "         30, 2242,    7,  127,   71,  673,   12,   26,  252,    5,   69,\n",
       "         19,    1,   29,  370,   40,   26, 3501,    2,  632,   30,    6,\n",
       "        645,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we pad the sequences\n",
    "max_length = 500\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "train_padded[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proceeding to the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "emb_dim = 128 # 128\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4456, 500), (4456, 5), (1114, 500), (1114, 5))\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, 500, 128)          640000    \n",
      "                                                                 \n",
      " spatial_dropout1d_11 (Spat  (None, 500, 128)          0         \n",
      " ialDropout1D)                                                   \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 689733 (2.63 MB)\n",
      "Trainable params: 689733 (2.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "14/14 [==============================] - 23s 1s/step - loss: 1.6104 - acc: 0.2001 - val_loss: 1.6095 - val_acc: 0.1906\n",
      "Epoch 2/3\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.6099 - acc: 0.2012 - val_loss: 1.6102 - val_acc: 0.1906\n",
      "Epoch 3/3\n",
      "14/14 [==============================] - 20s 1s/step - loss: 1.6108 - acc: 0.1928 - val_loss: 1.6100 - val_acc: 0.2085\n"
     ]
    }
   ],
   "source": [
    "print((train_padded.shape, train_labels.shape, test_padded.shape, test_labels.shape))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, emb_dim, input_length=max_length))\n",
    "model.add(SpatialDropout1D(0.5))\n",
    "model.add(LSTM(64, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "history = model.fit(train_padded, train_labels, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=7, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we predict the test labels\n",
    "test_pred = model.predict(test_padded)\n",
    "\n",
    "# for each vector, we put the max value to 1 and the others to 0\n",
    "test_pred = np.where(test_pred == np.amax(test_pred, axis=1, keepdims=True), 1, 0)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19210053859964094"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test_labels, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 11s 55ms/step - loss: 0.9233 - acc: 0.7301\n",
      "Test set\n",
      "  Loss: 0.923\n",
      "  Accuracy: 0.730\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(train_padded,train_labels)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we evaluate the model\n",
    "# model.evaluate(test_padded, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we predict the test labels\n",
    "# test_pred = model.predict(test_padded)\n",
    "# test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
